{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace56383",
   "metadata": {},
   "source": [
    "# 사진 크롤링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b1578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common import keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os, urllib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0088d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d940dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/2432694325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 데이터 라벨 가져오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_file/여행지 라벨.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_file/나라별 여행지 라벨.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 데이터 라벨 가져오기\n",
    "df1 = pd.read_excel('data_file/여행지 라벨.xlsx')\n",
    "df2 = pd.read_excel('data_file/나라별 여행지 라벨.xlsx')\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "70441d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 필요한 columns만 가져오기\n",
    "datas = df2[['en나라', 'en관광지']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8bd39",
   "metadata": {},
   "source": [
    "## 크롤링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9d25c025",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 Campanile di San Marco downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1449 download successful\n",
      "1500 Leaning Tower of Pisa downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Staromestske namesti downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Blue Mosque downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Basilica Cistern downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1426 download successful\n",
      "1458 Hadrian's Gate downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1427 download successful\n",
      "1500 Louvre Museum downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Eiffel Tower downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Cathedrale Notre-Dame de Paris downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Arc de Triomphe downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1110 Sainte-Chapelle downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 1110 download successful\n",
      "1043 Moulin Rouge downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 1043 download successful\n",
      "1500 Hotel de Ville downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1448 download successful\n",
      "446 Manneken Pis downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 446 download successful\n",
      "1500 St. Stephen's Cathedral downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1457 download successful\n",
      "1500 Torre de Belem downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Mosteiro dos Jeronimos downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "890 Panteao Nacional downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 890 download successful\n",
      "1500 Padrao dos Descobrimentos downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1447 download successful\n",
      "736 Se de Lisboa downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 736 download successful\n",
      "1500 Chapel Bridge downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1475 download successful\n",
      "1500 Basel Minster downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1430 download successful\n",
      "119 Grgur Ninski Statue downloading... 1 2 3 4 5 119 download successful\n",
      "1500 Zadar Cathedral downloading... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 1424 download successful\n"
     ]
    }
   ],
   "source": [
    "page_limit = 25\n",
    "page_num = 60\n",
    "\n",
    "\n",
    "for data in datas[23:]:\n",
    "    country = data[0]\n",
    "    search_name = data[1]\n",
    "    count = 0\n",
    "    res = requests.get(f\"https://stock.adobe.com/kr/search/images?filters%5Bcontent_type%3Aphoto%5D=1&filters%5Bcontent_type%3Aimage%5D=1&filters%5Breleases%3Ais_exclude%5D=1&k={search_name}&order=relevance&safe_search=1&search_type=usertyped&limit={page_limit-1}&search_page=1&acp=&aco={search_name}&get_facets=1\")\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    string = soup.select('strong.text-sregular')[0].text\n",
    "    img_num = int(re.sub(r'[^0-9]', '', string))\n",
    "    max_count = page_limit * page_num\n",
    "    if max_count > img_num:\n",
    "        max_count = img_num\n",
    "    print(f\"{max_count} {search_name} downloading...\")\n",
    "    for page in range(1, page_num):\n",
    "        res = requests.get(f\"https://stock.adobe.com/kr/search/images?filters%5Bcontent_type%3Aphoto%5D=1&filters%5Bcontent_type%3Aimage%5D=1&filters%5Breleases%3Ais_exclude%5D=1&k={search_name}&order=relevance&safe_search=1&search_type=usertyped&limit={page_limit-1}&search_page={page}&acp=&aco={search_name}&get_facets=1\")\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        div = soup.select('picture > source')\n",
    "        for i, img in enumerate(div):\n",
    "            url = img['srcset']\n",
    "            \n",
    "            ## 유럽 나라별 크롤링\n",
    "            if not os.path.exists(f\"country_img/{country}\"):\n",
    "                os.makedirs(f\"country_img/{country}\")\n",
    "            urllib.request.urlretrieve(url, f\"country_img/{country}/{search_name + str(count)}.jpg\")\n",
    "            \n",
    "            ## 나라별/ 관광지별 크롤링\n",
    "#             if not os.path.exists(f\"img/{country}/{search_name}\"):\n",
    "#                 os.makedirs(f\"img/{country}/{search_name}\")\n",
    "#             urllib.request.urlretrieve(url, f\"img/{country}/{search_name}/{count}.jpg\")\n",
    "\n",
    "            ## imagedatagenerator용 train,validation,test별 크롤링\n",
    "#             if count <= (max_count * 0.6):\n",
    "#                 if not os.path.exists(f\"img_gen/train/{search_name}\"):\n",
    "#                     os.makedirs(f\"img_gen/train/{search_name}\")\n",
    "#                 urllib.request.urlretrieve(url, f\"img_gen/train/{search_name}/{count}.jpg\")\n",
    "#             elif count <= (max_count * 0.8):\n",
    "#                 if not os.path.exists(f\"img_gen/validataion/{search_name}\"):\n",
    "#                     os.makedirs(f\"img_gen/validataion/{search_name}\")\n",
    "#                 urllib.request.urlretrieve(url, f\"img_gen/validataion/{search_name}/{count}.jpg\")\n",
    "#             else:\n",
    "#                 if not os.path.exists(f\"img_gen/test/{search_name}\"):\n",
    "#                     os.makedirs(f\"img_gen/test/{search_name}\")\n",
    "#                 urllib.request.urlretrieve(url, f\"img_gen/test/{search_name}/{count}.jpg\")\n",
    "                \n",
    "            count += 1\n",
    "        print(page)\n",
    "        if count >= max_count:\n",
    "            break\n",
    "    \n",
    "    print(f\"{count} download successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f7e8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "100 download successful\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 원하는 나라 1곳만 크롤링\n",
    "page_limit = 25\n",
    "page_num = 5\n",
    "crawling_num = 20\n",
    "\n",
    "country = 'China'\n",
    "search_name = 'qin terracotta warriors'\n",
    "count = 0\n",
    "for page in range(page_num):\n",
    "    res = requests.get(f\"https://stock.adobe.com/kr/search/images?filters%5Bcontent_type%3Aphoto%5D=1&filters%5Bcontent_type%3Aimage%5D=1&filters%5Breleases%3Ais_exclude%5D=1&k={search_name}&order=relevance&safe_search=1&search_type=usertyped&limit={page_limit - 1}&search_page={page}&acp=&aco={search_name}&get_facets=1\")\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    div = soup.select('picture > source')[:20]\n",
    "    for i, img in enumerate(div):\n",
    "        url = img['srcset']\n",
    "        if not os.path.exists(f\"img/{country}\"):\n",
    "            os.makedirs(f\"img/{country}\")\n",
    "        if not os.path.exists(f\"img/{country}/{search_name}\"):\n",
    "            os.makedirs(f\"img/{country}/{search_name}\")\n",
    "        urllib.request.urlretrieve(url, f\"img/{country}/{search_name}/{count}.jpg\")\n",
    "        #print(\"download successful\")\n",
    "        count += 1\n",
    "print('=' * 50)\n",
    "print(country, count, 'download successful')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9b3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
